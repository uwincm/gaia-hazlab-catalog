{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d9071ce",
   "metadata": {},
   "source": [
    "# Created a Merged Station Inventory for GAIA / CRESST\n",
    "\n",
    "Focus on WA State for now\n",
    "\n",
    "Precip stations https://docs.synopticdata.com/services/metadata\n",
    "\n",
    "Requires an academic account + token for interfacing with API \n",
    "\n",
    "\n",
    "TODO:\n",
    "- create merged inventory (maybe STAC)\n",
    "- set end_datetime = NaT if today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# seismic\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00d9f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = os.environ.get('SYNOPTIC_TOKEN')\n",
    "\n",
    "baseAPI = \"https://api.synopticdata.com/v2\"\n",
    "endpoint = \"/stations/metadata\"\n",
    "url = baseAPI + endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28bf42a",
   "metadata": {},
   "source": [
    "## Precipitation\n",
    "\n",
    "\n",
    "### SNOTEL \n",
    "\n",
    "keep these separate b/c they are special "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aced5e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate SNOTEL as separate inventory?\n",
    "#network=SNOTEL ... must be a number\n",
    "# https://docs.synopticdata.com/services/networks\n",
    "# You can find mapping here https://demos.synopticdata.com/providers/index.html\n",
    "#vars=SWE,SNOWDEPTH\n",
    "params = dict(state=\"wa\",\n",
    "              token=TOKEN,\n",
    "              sensorvars=True, # return sensor variable info\n",
    "              network=25, # SNOTEL\n",
    "              output='geojson', # does not return sensor_vars :(\n",
    ")\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "gf_snotel = gpd.GeoDataFrame.from_features(data['features'], crs='EPSG:4326')\n",
    "print(len(gf_snotel))\n",
    "gf_snotel.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ea0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_snotel.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b1840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_snotel['start_datetime'] = pd.to_datetime(gf_snotel['period_of_record'].apply(lambda x: x['start']))\n",
    "gf_snotel['end_datetime'] = pd.to_datetime(gf_snotel['period_of_record'].apply(lambda x: x['end']))\n",
    "gf_snotel.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe51a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if end datetime date is today & remove timezone (UTC from API)\n",
    "\n",
    "gf_snotel['start_datetime'] = gf_snotel['start_datetime'].dt.tz_localize(None)\n",
    "\n",
    "def null_if_today(date):\n",
    "    today_utc = pd.Timestamp.today(tz='UTC').date()\n",
    "    return pd.NaT if date.tz_localize(None).date() == today_utc else date.tz_localize(None)\n",
    "\n",
    "\n",
    "gf_snotel['end_datetime'] = gf_snotel['end_datetime'].apply(null_if_today)\n",
    "gf_snotel.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83f0d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are inactive very out of date or not?\n",
    "gf_snotel[gf_snotel.status=='INACTIVE'].sort_values('end_datetime')[['stid','name','start_datetime','end_datetime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a7cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: sometimes you get\n",
    "# ConnectionError: HTTPSConnectionPool(host='api.synopticdata.com', port=443): Max retries exceeded with url: /v2/stations/metadata?state=wa&token=101c46711eb84aa792716a38e4ca9906&sensorvars=True&network=25&output=json (Caused by NameResolutionError(\"HTTPSConnection(host='api.synopticdata.com', port=443): Failed to resolve 'api.synopticdata.com' ([Errno 8] nodename nor servname provided, or not known)\"))\n",
    "\n",
    "def add_sensor_variables(gdf, network_code=None):\n",
    "    \"\"\"Add sensor variable names as a list in a new column.\"\"\"\n",
    "    params = dict(state=\"wa\",\n",
    "              token=TOKEN,\n",
    "              sensorvars=True, # return sensor variable info\n",
    "              network=network_code, # SNOTEL\n",
    "              output='json', # does not return sensor_vars :(\n",
    "    )\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data['STATION'])\n",
    "    return df.SENSOR_VARIABLES.apply(lambda x: list(x.keys()))\n",
    "\n",
    "add_sensor_variables(gf_snotel, network_code=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94406f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_snotel.iloc[0].SENSOR_VARIABLES.keys()\n",
    "gf_snotel['sensor_variables'] = add_sensor_variables(gf_snotel, network_code=25)\n",
    "gf_snotel.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2324d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: not all have wind speed or soil temp for example...\n",
    "gf_snotel['sensor_variables'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8204d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make links clickable in the station inventory table\n",
    "gf_snotel['station_info'] = gf_snotel['station_info'].apply(lambda x: f'<a href=\"{x}\" target=\"_blank\">{x}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d406975",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = ['geometry','id','stid','name','longitude','latitude','elevation','status','start_datetime','end_datetime','station_info', 'sensor_variables']\n",
    "gf_snotel[keep_cols].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_snotel[keep_cols].explore(popup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb819708",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_snotel[keep_cols].to_file('snotel_stations.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bda54d2",
   "metadata": {},
   "source": [
    "## Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ebabfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter search to stations with precip data\n",
    "# https://demos.synopticdata.com/variables/index.html\n",
    "precip_vars = [\"precip_accum\"] # NOTE: there are a lot! e.g. hourly etc\n",
    "sensorvars=True\n",
    "\n",
    "params = dict(state=\"wa\",\n",
    "              token=TOKEN,\n",
    "              network='!25', # NOT SNOTEL\n",
    "              sensorvars=True, # return sensor variable info\n",
    "              vars=','.join(precip_vars), # restrict to precip only\n",
    "              output='geojson',\n",
    ")\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ff3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfp = gpd.GeoDataFrame.from_features(data['features'], crs='EPSG:4326')\n",
    "print('Number of precip stations:', len(gfp))\n",
    "gfp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101dd822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many different networks for precip.... a lot!\n",
    "# probably different sensor types too\n",
    "print('Number of networks:', gfp.mnet_id.nunique())\n",
    "#gfp.mnet_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A rogue statio in Mexico!\n",
    "gfp = gfp[gfp.stid != 'E0744']\n",
    "\n",
    "#gfp.explore(column='status',popup=True, cmap=['green','red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee624cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gfp.to_file('precip-stations-wa.geojson', driver='GeoJSON')\n",
    "# For starters drop Inactive and restricted sensors\n",
    "keep_cols = ['geometry','id','stid','name', 'longitude','latitude','elevation','mnet_id', 'status','period_of_record','station_info','restricted_data']\n",
    "gfp = gfp[(gfp.status == 'ACTIVE') & (gfp.restricted_data == False)][keep_cols]\n",
    "print(len(gfp), \"active, unrestricted precip stations in WA\")\n",
    "gfp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136ff612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add separate columns for period_of_record start and end\n",
    "gfp['start_datetime'] = pd.to_datetime(gfp['period_of_record'].apply(lambda x: x['start']))\n",
    "gfp['end_datetime'] = pd.to_datetime(gfp['period_of_record'].apply(lambda x: x['end']))\n",
    "new_order = [\"id\", \"stid\", \"name\", \"longitude\", \"latitude\", \"elevation\", \"mnet_id\", \"start_datetime\", \"end_datetime\", \"station_info\", \"geometry\"]\n",
    "gfp = gfp[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc96685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if end datetime date is today & remove timezone (UTC from API)\n",
    "\n",
    "gfp['start_datetime'] = gfp['start_datetime'].dt.tz_localize(None)\n",
    "gfp['end_datetime'] = gfp['end_datetime'].apply(null_if_today)\n",
    "gfp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06cd6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add list of variables\n",
    "gfp['sensor_variables'] = add_sensor_variables(gfp, network_code=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d60fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfp['sensor_variables'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b529f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sensor_vars = gfp['sensor_variables'].explode()\n",
    "all_precip_vars = set([x for x in all_sensor_vars if str(x).startswith('precip')])\n",
    "all_precip_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba0152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lots of different ways of measuring precip... not sure how to handle this yet\n",
    "for var in all_precip_vars:\n",
    "    print(f\"Number of stations with {var}:\",\n",
    "          len(gfp[gfp['sensor_variables'].apply(lambda x: var in x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edaf8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any without precip? yup!\n",
    "# But looking at the station website it does have precip, so maybe some metadata is incomplete...\n",
    "no_precip = gfp[~gfp['sensor_variables'].apply(lambda x: any(var in x for var in all_precip_vars))]\n",
    "len(no_precip)\n",
    "no_precip.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98276b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95115d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But actually, looking at station page, there is precip. It's just under precip_accum_1 for some reason\n",
    "# https://explore.synopticdata.com/KMFW1/metadata\n",
    "\n",
    "def get_single_station_precip_timeseries(stid, start, end, derived=0):\n",
    "    endpoint = \"/stations/timeseries\"\n",
    "    url = baseAPI + endpoint\n",
    "\n",
    "    params = dict(token = TOKEN,\n",
    "                stid = stid,\n",
    "                start = start,\n",
    "                end = end,\n",
    "                vars = 'precip',\n",
    "                precip = derived  # Enable derived precip (precip_accumulated_set_1d, precip_intervals_set_1d)\n",
    "                #precip =0 (default) 'precip_accum_set_1' (Millimeters) cumulative sum of the interval values for the requested time period, in this case hourly timestamps\n",
    "    )\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    print(data)\n",
    "    print(data['UNITS'])\n",
    "    df = pd.DataFrame(data['STATION'][0]['OBSERVATIONS'])\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    return df\n",
    "\n",
    "# START must be a number in the form YYYYmmddHHMM.\n",
    "\n",
    "start = pd.Timestamp('2025-12-01').strftime('%Y%m%d%H%M')\n",
    "end = pd.Timestamp('2025-12-31').strftime('%Y%m%d%H%M')\n",
    "df = get_single_station_precip_timeseries('KMFW1', start, end, derived=True)\n",
    "\n",
    "# According to # https://raws.dri.edu/cgi-bin/wea_mnsimts2.pl\n",
    "# total of 38.1 mm in december\n",
    "print('Monthly total =', df.precip_accumulated_set_1d.iloc[-1])\n",
    "\n",
    "#print(df.head())\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "df.plot(ax=ax, x='date_time', y='precip_accumulated_set_1d')\n",
    "df.plot(ax=ax, x='date_time', y='precip_intervals_set_1d')\n",
    "plt.ylabel('Millimeters');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e816b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: if derived=False, starting value != 0\n",
    "# # weird, according to https://raws.dri.edu/cgi-bin/rawMAIN.pl?waWKRA  72.39 is the accumulated total precip from last 2 months...\n",
    "# whiich is what we get as a starting value...\n",
    "df = get_single_station_precip_timeseries('KMFW1', start, end, derived=False)\n",
    "df.head()\n",
    "print(df.iloc[0])\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "df.plot(ax=ax, x='date_time', y='precip_accum_set_1')\n",
    "plt.ylabel('Millimeters');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6574ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make station_info URL a clickable link\n",
    "gfp['station_info'] = gfp['station_info'].apply(lambda x: f'<a href=\"{x}\" target=\"_blank\">{x}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e22f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add simple-styling for geojson.io\n",
    "# https://github.com/mapbox/simplestyle-spec/blob/master/1.1.0/README.md\n",
    "# gfp['marker-color'] = '#0000FF' # blue\n",
    "# gfp['marker-size'] = 'small'\n",
    "# gfp['marker-symbol'] = 'water'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfp.explore(popup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183615ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save simplified, styled geojson\n",
    "gfp.to_file(\"precip-stations.geojson\", driver='GeoJSON')\n",
    "!ls -tlrh *geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2117024b",
   "metadata": {},
   "source": [
    "## Streamflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3637a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search USGS River Gauges:\n",
    "# filter search to stations with precip data\n",
    "# https://demos.synopticdata.com/variables/index.html\n",
    "target_vars = [\"stream_flow\"]\n",
    "sensorvars=True\n",
    "\n",
    "params = dict(state=\"wa\",\n",
    "              token=TOKEN,\n",
    "              #sensorvars=True, # Doesn't seem to work for geojson output...\n",
    "              vars=','.join(target_vars),\n",
    "              output='geojson',\n",
    ")\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e30862",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs = gpd.GeoDataFrame.from_features(data['features'], crs='EPSG:4326')\n",
    "print('stations=', len(gfs))\n",
    "gfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only ACTIVE sensores Add separate columns for period_of_record start and end\n",
    "gfs = gfs[(gfs.status == 'ACTIVE')][keep_cols]\n",
    "\n",
    "gfs['start_datetime'] = pd.to_datetime(gfs['period_of_record'].apply(lambda x: x['start']))\n",
    "gfs['end_datetime'] = pd.to_datetime(gfs['period_of_record'].apply(lambda x: x['end']))\n",
    "\n",
    "# Check if end datetime date is today & remove timezone (UTC from API)\n",
    "gfs['start_datetime'] = gfs['start_datetime'].dt.tz_localize(None)\n",
    "gfs['end_datetime'] = gfs['end_datetime'].apply(null_if_today)\n",
    "gfs.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a4a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs['station_info'] = gfs['station_info'].apply(lambda x: f'<a href=\"{x}\" target=\"_blank\">{x}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a988f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs['sensor_variables'] = add_sensor_variables(gfs, network_code=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b79572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = [\"id\", \"stid\", \"name\", \"longitude\", \"latitude\", \"elevation\", \"mnet_id\", \"start_datetime\", \"end_datetime\", \"station_info\", \"sensor_variables\", \"geometry\"]\n",
    "gfs = gfs[new_order]\n",
    "gfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b08eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b03957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gfs['marker-color'] = '#00FFFF' # cyan\n",
    "# gfs['marker-size'] = 'small'\n",
    "# gfs['marker-symbol'] = 'waterfall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05772b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save simplified, styled geojson\n",
    "gfs.to_file(\"streamflow-stations.geojson\", driver='GeoJSON')\n",
    "!ls -tlrh *geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768a3a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine both precip and streamflow\n",
    "gf = pd.concat([gfp, gfs], ignore_index=True)\n",
    "print('Total stations (precip + streamflow)=', len(gf))\n",
    "# gf.head()\n",
    "# gf.to_file('combined-stations-wa-styled.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d04a94",
   "metadata": {},
   "source": [
    "## Seismic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5601c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client('IRIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330124bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = gpd.read_file(\n",
    "    \"https://raw.githubusercontent.com/unitedstates/districts/refs/heads/gh-pages/states/WA/shape.geojson\"\n",
    ")\n",
    "minlon, minlat, maxlon, maxlat = aoi.total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac79dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "staqkwargs = {\n",
    "    'channel': 'EHZ,HHZ,ENZ,HNZ,BNZ',\n",
    "    'minlatitude': minlat,\n",
    "    'minlongitude': minlon,\n",
    "    'maxlongitude': maxlon,\n",
    "    'maxlatitude': maxlat,\n",
    "    'starttime': UTCDateTime('2025-01-01'),\n",
    "    'endtime': UTCDateTime('2025-12-31'),\n",
    "    'level': 'station'\n",
    "}\n",
    "\n",
    "# Query stations\n",
    "inv = client.get_stations(**staqkwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41797a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inv.networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964ba99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsll_set = set()\n",
    "for net in inv.networks:\n",
    "    for sta in net.stations:\n",
    "        tup = (net.code,\n",
    "               sta.code,\n",
    "               sta.longitude,\n",
    "               sta.latitude,\n",
    "               sta.elevation,\n",
    "               sta.start_date.datetime,\n",
    "               sta.end_date.datetime if sta.end_date else None,\n",
    "               #sta.total_number_of_channels,\n",
    "               sta.is_active(),\n",
    "               f'https://ds.iris.edu/mda/{net.code}/{sta.code}'\n",
    "        )\n",
    "        nsll_set.add(tup)\n",
    "\n",
    "# 'total_number_of_channels'\n",
    "df_seis = pd.DataFrame(list(nsll_set), columns=['network','station','longitude','latitude','elevation','start_datetime','end_datetime', 'is_active', 'station_info'])\n",
    "df_seis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab210ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_seis), \"active seismic stations in WA State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441fd3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_seis['marker-color'] = '#FF00FF' # magenta\n",
    "# df_seis['marker-size'] = 'small'\n",
    "# df_seis['marker-symbol'] = 'defibrillator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1547ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seis['station_info'] = df_seis['station_info'].apply(lambda x: f'<a href=\"{x}\" target=\"_blank\">{x}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37cf3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas to GeoPandas\n",
    "gf_seis = gpd.GeoDataFrame(df_seis, geometry=gpd.points_from_xy(df_seis.longitude, df_seis.latitude), crs='EPSG:4326')\n",
    "gf_seis.explore(popup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a57dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gf_seis = gf_seis.drop(columns=['is_active'])\n",
    "gf_seis.to_file('seismic-stations.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e43a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideally use same schema across data providers...\n",
    "#gf_seis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1a1f29",
   "metadata": {},
   "source": [
    "### Infrasound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44957f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "staqkwargs = {\n",
    "    'channel': 'BDF',\n",
    "    'minlatitude': minlat,\n",
    "    'minlongitude': minlon,\n",
    "    'maxlongitude': maxlon,\n",
    "    'maxlatitude': maxlat,\n",
    "    'starttime': UTCDateTime('2025-01-01'),\n",
    "    'endtime': UTCDateTime('2025-12-31'),\n",
    "    'level': 'station'\n",
    "}\n",
    "\n",
    "# Query stations\n",
    "inv = client.get_stations(**staqkwargs)\n",
    "len(inv.networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8bc39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsll_set = set()\n",
    "for net in inv.networks:\n",
    "    for sta in net.stations:\n",
    "        tup = (net.code,\n",
    "               sta.code,\n",
    "               sta.longitude,\n",
    "               sta.latitude,\n",
    "               sta.elevation,\n",
    "               sta.start_date.datetime,\n",
    "               sta.end_date.datetime if sta.end_date else None,\n",
    "               #sta.total_number_of_channels,\n",
    "               sta.is_active(),\n",
    "               f'https://ds.iris.edu/mda/{net.code}/{sta.code}'\n",
    "        )\n",
    "        nsll_set.add(tup)\n",
    "\n",
    "# 'total_number_of_channels'\n",
    "df_infrasound = pd.DataFrame(list(nsll_set), columns=['network','station','longitude','latitude','elevation','start_datetime','end_datetime', 'is_active', 'station_info'])\n",
    "print(len(df_infrasound), \"active infrasound stations in WA State\")\n",
    "df_infrasound.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a35448",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infrasound['station_info'] = df_infrasound['station_info'].apply(lambda x: f'<a href=\"{x}\" target=\"_blank\">{x}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c4c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_infra = gpd.GeoDataFrame(df_infrasound, geometry=gpd.points_from_xy(df_infrasound.longitude, df_infrasound.latitude), crs='EPSG:4326')\n",
    "gf_infra.explore(popup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1716289",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_infra.to_file('infrasound-stations.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e04275f",
   "metadata": {},
   "source": [
    "## GNSS\n",
    "\n",
    "\n",
    "TODO..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf5581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No time info\n",
    "#!wget -nc https://geodesy.unr.edu/gps_timeseries/IGS20/llh/llh.out\n",
    "!wget -nc https://geodesy.unr.edu/gps_timeseries/IGS20/llh/llh.out_sorted_by_add_date\n",
    "!head llh.out_sorted_by_add_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('llh.out_sorted_by_add_date', sep=r'\\s+',\n",
    "                 names=['station','lat','lon','elevation','datestr']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ffc156",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_datetime'] = pd.to_datetime(df['datestr'], format='%Y_%j')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02d9716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert longitude from -360 to 0 range to -180 to 180 range\n",
    "df['lon'] = df['lon'].apply(lambda x: x + 360 if x < -180 else x)\n",
    "\n",
    "# Create GeoDataFrame\n",
    "gf_gnss = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat), crs='EPSG:4326')\n",
    "gf_gnss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add station url plain text\n",
    "#gf_gnss['station_info'] = gf_gnss['station'].apply(lambda x: f'https://geodesy.unr.edu/NGLStationPages/stations/{x}.sta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18af478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hyperlink to station data\n",
    "# NOTE: doesn;t work in Jupyter Notebook, but does work in exported HTML\n",
    "gf_gnss['station_link'] = gf_gnss['station'].apply(lambda x: f'<a href=\"https://geodesy.unr.edu/NGLStationPages/stations/{x}.sta\" target=\"_blank\">{x}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a23166",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_gnss.iloc[-1].station_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5853c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = gpd.read_file(\n",
    "    \"https://raw.githubusercontent.com/unitedstates/districts/refs/heads/gh-pages/states/WA/shape.geojson\"\n",
    ")\n",
    "\n",
    "#gf_gnss.to_file('gnss.geojson') # 9MB\n",
    "clipped = gf_gnss.clip(aoi.geometry[0])\n",
    "clipped.to_file('wa_gnss.geojson') #126 KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ace93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltrh wa_gnss.geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = clipped.explore(popup=True)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df843e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save('gnss-stations-wa.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
